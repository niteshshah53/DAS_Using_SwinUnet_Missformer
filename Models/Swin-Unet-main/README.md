# Historical Document Segmentation - Advanced Deep Learning Models

This repository contains state-of-the-art deep learning models for historical document segmentation, featuring transformer-based architectures and hybrid CNN-transformer combinations optimized for manuscript analysis.

## ğŸ“ Directory Structure

```
Swin-Unet-main/
â”œâ”€â”€ models/                          # Model-specific implementations
â”‚   â”œâ”€â”€ sstrans/                     # Smart Swin Transformer
â”‚   â”‚   â”œâ”€â”€ train.py                 # SSTrans training script
â”‚   â”‚   â”œâ”€â”€ test.py                  # SSTrans testing script
â”‚   â”‚   â”œâ”€â”€ trainer.py               # SSTrans-specific trainer
â”‚   â”‚   â”œâ”€â”€ run.sh                   # SSTrans execution script
â”‚   â”‚   â”œâ”€â”€ Only_Smart.py            # Smart attention mechanism
â”‚   â”‚   â”œâ”€â”€ vision_transformer.py    # SSTrans model implementation
â”‚   â”‚   â””â”€â”€ ...                      # Other SSTrans-specific files
â”‚   â”œâ”€â”€ swinunet/                    # Swin Transformer U-Net
â”‚   â”‚   â”œâ”€â”€ train.py                 # SwinUnet training script
â”‚   â”‚   â”œâ”€â”€ test.py                  # SwinUnet testing script
â”‚   â”‚   â”œâ”€â”€ trainer.py               # SwinUnet-specific trainer
â”‚   â”‚   â”œâ”€â”€ run.sh                   # SwinUnet execution script
â”‚   â”‚   â”œâ”€â”€ swin_transformer_unet_skip_expand_decoder_sys.py  # Main model
â”‚   â”‚   â””â”€â”€ ...                      # Other SwinUnet-specific files
â”‚   â”œâ”€â”€ missformer/                  # MissFormer (Multi-scale Transformer)
â”‚   â”‚   â”œâ”€â”€ train.py                 # MissFormer training script
â”‚   â”‚   â”œâ”€â”€ test.py                  # MissFormer testing script
â”‚   â”‚   â”œâ”€â”€ trainer.py               # MissFormer-specific trainer
â”‚   â”‚   â”œâ”€â”€ run.sh                   # MissFormer execution script
â”‚   â”‚   â”œâ”€â”€ MISSFormer.py            # MissFormer model implementation
â”‚   â”‚   â”œâ”€â”€ segformer.py             # SegFormer backbone
â”‚   â”‚   â””â”€â”€ ...                      # Other MissFormer-specific files
â”‚   â””â”€â”€ hybrid/                      # Hybrid CNN-Transformer Models
â”‚       â”œâ”€â”€ hybrid1/                 # EfficientNet-Swin Hybrid
â”‚       â”‚   â”œâ”€â”€ hybrid_model.py      # Main hybrid model
â”‚       â”‚   â”œâ”€â”€ efficientnet_encoder.py  # EfficientNet-B4 encoder
â”‚       â”‚   â””â”€â”€ swin_decoder.py      # SwinUnet decoder
â”‚       â”œâ”€â”€ hybrid2/                 # Swin-EfficientNet Hybrid (Enhanced)
â”‚       â”‚   â”œâ”€â”€ hybrid_model.py      # Main hybrid model
â”‚       â”‚   â”œâ”€â”€ swin_encoder.py      # SwinUnet encoder
â”‚       â”‚   â””â”€â”€ efficientnet_decoder.py  # Enhanced EfficientNet decoder
â”‚       â”œâ”€â”€ train.py                 # Unified training script
â”‚       â”œâ”€â”€ test.py                  # Unified testing script
â”‚       â”œâ”€â”€ trainer.py               # Hybrid-specific trainer
â”‚       â”œâ”€â”€ augmentation.py          # Advanced data augmentation
â”‚       â”œâ”€â”€ run.sh                   # Hybrid1 execution script
â”‚       â”œâ”€â”€ run_hybrid2.sh           # Hybrid2 execution script
â”‚       â””â”€â”€ README.md                # Hybrid models documentation
â”œâ”€â”€ common/                          # Shared components
â”‚   â”œâ”€â”€ datasets/                    # Dataset implementations
â”‚   â”‚   â”œâ”€â”€ dataset_udiadsbib.py     # U-DIADS-Bib dataset loader
â”‚   â”‚   â”œâ”€â”€ dataset_divahisdb.py     # DivaHisDB dataset loader
â”‚   â”‚   â”œâ”€â”€ dataset_synapse.py       # Synapse dataset loader
â”‚   â”‚   â””â”€â”€ sstrans_transforms.py    # SSTrans-specific transforms
â”‚   â”œâ”€â”€ utils/                       # Utility functions
â”‚   â”‚   â””â”€â”€ utils.py                 # Common utilities (losses, metrics)
â”‚   â””â”€â”€ configs/                     # Configuration files
â”‚       â”œâ”€â”€ config.py                # Configuration management
â”‚       â””â”€â”€ swin_tiny_patch4_window7_224_lite.yaml
â”œâ”€â”€ run_all_models.sh               # Script to run all models
â””â”€â”€ requirements.txt                # Python dependencies
```

## ğŸš€ Quick Start

### Prerequisites

```bash
# Install dependencies
pip install -r requirements.txt

# Load Python environment (if using module system)
module load python/pytorch2.6py3.12
```

### Run Individual Models

Each model has its own execution script:

```bash
# SSTrans (Smart Swin Transformer with attention mechanisms)
cd models/sstrans
./run.sh

# SwinUnet (Standard Swin Transformer U-Net)
cd models/swinunet
./run.sh

# MissFormer (Multi-scale Transformer with SegFormer backbone)
cd models/missformer
./run.sh

# Hybrid1 (EfficientNet-B4 encoder + SwinUnet decoder)
cd models/hybrid
./run.sh

# Hybrid2 (SwinUnet encoder + Enhanced EfficientNet decoder)
cd models/hybrid
./run_hybrid2.sh
```

### Run All Models

```bash
# Run all models sequentially
./run_all_models.sh
```

### Custom Training

```bash
# Train Hybrid2 with custom parameters
cd models/hybrid
python3 train.py \
    --model hybrid2 \
    --efficientnet_variant b4 \
    --dataset UDIADS_BIB \
    --udiadsbib_root "../../U-DIADS-Bib-MS_patched" \
    --manuscript Latin2 \
    --use_patched_data \
    --batch_size 16 \
    --max_epochs 300 \
    --base_lr 0.0002 \
    --patience 30 \
    --output_dir "./results/hybrid2_latin2"
```

## ğŸ”§ Model Architectures & Configurations

### SSTrans (Smart Swin Transformer)
- **Architecture**: Enhanced Swin Transformer with smart attention mechanisms
- **Key Features**: 
  - Smart attention masks for improved focus
  - Heavy data augmentation pipeline
  - Advanced normalization strategies
- **Training**: Standardized with validation and early stopping
- **Loss Function**: 0.4 * CE + 0.2 * Focal + 0.4 * Dice (no class weights)
- **Optimizer**: AdamW with weight_decay=0.01
- **Validation**: Sliding window on full images

### SwinUnet (Swin Transformer U-Net)
- **Architecture**: Standard Swin Transformer with U-Net decoder
- **Key Features**:
  - Skip connections between encoder and decoder
  - Patch merging and expanding operations
  - Window-based self-attention
- **Training**: Standardized with validation and early stopping
- **Loss Function**: 0.4 * CE + 0.0 * Focal + 0.6 * Dice (no class weights)
- **Optimizer**: AdamW with weight_decay=0.01
- **Validation**: Sliding window on full images

### MissFormer (Multi-scale Transformer)
- **Architecture**: SegFormer backbone with multi-scale feature fusion
- **Key Features**:
  - Efficient self-attention mechanisms
  - Multi-scale feature aggregation
  - Bridge layers for feature fusion
- **Training**: Advanced with class weights and sliding window validation
- **Loss Function**: 0.4 * CE + 0.0 * Focal + 0.6 * Dice (with class weights)
- **Optimizer**: AdamW with weight_decay=1e-4
- **Validation**: Advanced sliding window with mask conversion

### Hybrid1 (EfficientNet-Swin)
- **Architecture**: EfficientNet-B4 encoder + SwinUnet decoder
- **Key Features**:
  - CNN-based feature extraction
  - Transformer-based decoding
  - Channel adaptation layers
- **Training**: Standardized with conditional focal loss
- **Loss Function**: 0.4 * CE + 0.2 * Focal + 0.4 * Dice (no class weights)
- **Optimizer**: AdamW with weight_decay=0.01
- **Validation**: Standard DataLoader validation

### Hybrid2 (Swin-EfficientNet Enhanced)
- **Architecture**: SwinUnet encoder + Enhanced EfficientNet decoder
- **Key Features**:
  - **CBAM Attention**: Channel and spatial attention mechanisms
  - **Feature Refinement**: Gradual channel reduction with residual connections
  - **Smart Skip Connections**: Attention-based feature fusion
  - **Deep Decoder Blocks**: Multi-layer convolutions with attention
  - **Enhanced Augmentation**: Advanced data augmentation pipeline
- **Training**: Standardized with conditional focal loss
- **Loss Function**: 0.4 * CE + 0.2 * Focal + 0.4 * Dice (no class weights)
- **Optimizer**: AdamW with weight_decay=0.01
- **Validation**: Standard DataLoader validation
- **Variants**: B0 (lightweight), B4 (balanced), B5 (heavy)

## ğŸ“Š Supported Datasets

### U-DIADS-Bib
- **Description**: Historical manuscript segmentation dataset
- **Classes**: 6 classes (5 for Syriaque341 manuscripts)
- **Classes**: Background, Paratext, Decoration, Main Text, Title, Chapter Headings
- **Note**: Syriaque341 manuscripts don't have Chapter Headings (5 classes)
- **Format**: RGB color-coded masks
- **Usage**: `--dataset UDIADS_BIB --use_patched_data`

### DIVAHISDB
- **Description**: Historical document analysis dataset
- **Classes**: 4 classes
- **Classes**: Background, Comment, Decoration, Main Text
- **Format**: Bitmask-encoded masks
- **Usage**: `--dataset DIVAHISDB --use_patched_data`

### Synapse
- **Description**: Medical image segmentation dataset
- **Classes**: Variable (typically 9 classes)
- **Format**: HDF5 format
- **Usage**: `--dataset Synapse`

## ğŸ”§ Key Benefits of Repository Structure

1. **Modularity**: Each model is self-contained with its own implementation
2. **Flexibility**: Easy to experiment with different architectures
3. **Maintainability**: Clear separation between model-specific and shared code
4. **Extensibility**: Simple to add new models or modify existing ones
5. **Reproducibility**: Consistent training and evaluation pipelines

## ğŸ“ Adding New Models

To add a new model:

1. Create a new folder in `models/`
2. Copy the structure from an existing model (recommend starting with `hybrid/`)
3. Implement your model architecture
4. Modify the training/testing scripts
5. Update the common trainer if needed
6. Add the model to `run_all_models.sh`

## ğŸ› Troubleshooting

### Common Issues

#### Import Errors
- Ensure you're running scripts from the correct directory
- Check that the common directory is in the Python path
- Verify Python environment is properly loaded (`module load python/pytorch2.6py3.12`)

#### Model-Specific Issues
- **SSTrans**: Requires config file (`--cfg` parameter)
- **Hybrid Models**: Check `--model` parameter (hybrid1 vs hybrid2)
- **MissFormer**: Verify SegFormer dependencies
- Check individual `trainer.py` files for model-specific logic

#### Training Issues
- **CUDA Memory**: Reduce batch size if encountering OOM errors
- **Data Loading**: Ensure dataset paths are correct and accessible
- **Checkpoints**: Verify checkpoint paths and model compatibility

#### Performance Issues
- **Slow Training**: Consider reducing image size or using mixed precision
- **Poor Convergence**: Adjust learning rate or try different optimizers
- **Overfitting**: Increase regularization or use more data augmentation

## ğŸ“ˆ Model Performance Comparison

| Model | Architecture | Parameters | Memory | Speed | Best For |
|-------|-------------|-----------|--------|-------|----------|
| SSTrans | Smart Swin Transformer | ~28M | Moderate | Fast | Attention-focused tasks |
| SwinUnet | Standard Swin U-Net | ~27M | Moderate | Fast | General segmentation |
| MissFormer | Multi-scale Transformer | ~30M | High | Moderate | Multi-scale features |
| Hybrid1 | EfficientNet-Swin | ~50M | Moderate | Fast | CNN-Transformer fusion |
| Hybrid2 | Swin-EfficientNet | ~45M | Moderate | Moderate | Enhanced feature extraction |

## ğŸ”„ Recent Updates & Improvements

### Hybrid2 Enhancements (Latest)
- **CBAM Attention**: Channel and spatial attention mechanisms for better feature focus
- **Feature Refinement**: Gradual channel reduction with residual connections
- **Smart Skip Connections**: Attention-based feature fusion instead of simple concatenation
- **Deep Decoder Blocks**: Multi-layer convolutions with attention for better reconstruction
- **Enhanced Augmentation**: Advanced data augmentation pipeline with MixUp/CutMix

### Training Standardization
- **All Models**: AdamW optimizer with ReduceLROnPlateau scheduler
- **Early Stopping**: Consistent patience=30 epochs across all models
- **Validation**: Proper validation during training with sliding window for transformer models
- **Logging**: Improved TensorBoard logging and progress tracking
- **Checkpointing**: Automatic best model saving and cleanup

### Key Technical Improvements
1. **Attention Mechanisms**: CBAM and smart attention for better feature focus
2. **Skip Connections**: Intelligent fusion instead of simple concatenation
3. **Residual Learning**: Better gradient flow and training stability
4. **Multi-scale Processing**: Enhanced feature extraction at different scales
5. **Advanced Augmentation**: MixUp, CutMix, and sophisticated transforms

### Future Enhancements
- **Deep Supervision**: Optional auxiliary outputs for better training
- **Model Ensembling**: Combining multiple models for improved performance
- **Efficient Variants**: Lightweight versions for deployment
- **Cross-dataset Training**: Multi-dataset learning capabilities

This repository provides a comprehensive framework for historical document segmentation with state-of-the-art models and best practices.
